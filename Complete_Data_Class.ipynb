{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk, codecs\n",
    "from nltk import word_tokenize\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# to use my own preprocessing in the vectorizer later\n",
    "def my_dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209713 entries, 0 to 209712\n",
      "Data columns (total 4 columns):\n",
      "#           209713 non-null object\n",
      "Answers     209713 non-null object\n",
      "Class       209713 non-null object\n",
      "Subclass    209713 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ MB\n",
      "None \n",
      "\n",
      "M     85879\n",
      "L     40960\n",
      "F     37558\n",
      "A     35385\n",
      "0      9918\n",
      "\\N       13\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "after cleaning...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209700 entries, 0 to 209699\n",
      "Data columns (total 5 columns):\n",
      "index       209700 non-null int64\n",
      "#           209700 non-null object\n",
      "Answers     209700 non-null object\n",
      "Class       209700 non-null object\n",
      "Subclass    209700 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 8.0+ MB\n",
      "None\n",
      "M    85879\n",
      "L    40960\n",
      "F    37558\n",
      "A    35385\n",
      "0     9918\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "<bound method NDFrame.head of          index                             #  \\\n",
      "0            0      185124138106620081063215   \n",
      "1            1      185124138106620081063215   \n",
      "2            2      185124138106620081063215   \n",
      "3            3    52122529750377312346781011   \n",
      "4            4    52122529750377312346781011   \n",
      "5            5    52122529750377312346781011   \n",
      "6            6    52122529750377312346781011   \n",
      "7            7    52122529750377312346781011   \n",
      "8            8    52122529750377312346781011   \n",
      "9            9    52122529750377312346781011   \n",
      "10          10    52122529750377312346781011   \n",
      "11          11    52122529750377312346781011   \n",
      "12          12    52122529750377312346781011   \n",
      "13          13    52122529750377312346781011   \n",
      "14          14    52122529750377312346781011   \n",
      "15          15    52122529750377312346781011   \n",
      "16          16    52122529750377312346781011   \n",
      "17          17    52122529750377312346781011   \n",
      "18          18  4812248500709191234567891011   \n",
      "19          19  4812248500709191234567891011   \n",
      "20          20  4812248500709191234567891011   \n",
      "21          21  4812248500709191234567891011   \n",
      "22          22  4812248500709191234567891011   \n",
      "23          23  4812248500709191234567891011   \n",
      "24          24  4812248500709191234567891011   \n",
      "25          25  4812248500709191234567891011   \n",
      "26          26  4812248500709191234567891011   \n",
      "27          27  4812248500709191234567891011   \n",
      "28          28  4812248500709191234567891011   \n",
      "29          29  4812248500709191234567891011   \n",
      "...        ...                           ...   \n",
      "209670  209683        1213731965505291831K15   \n",
      "209671  209684        1213731965505291831K15   \n",
      "209672  209685        1213731965505291831K15   \n",
      "209673  209686        1213731965505291831K15   \n",
      "209674  209687        1213731965505291831K15   \n",
      "209675  209688        1213731965505291831K15   \n",
      "209676  209689        1213731965505291831K15   \n",
      "209677  209690        1213731965505291831K15   \n",
      "209678  209691        1213731965505291831K15   \n",
      "209679  209692        1213731965505291831K15   \n",
      "209680  209693        1213731965505291831K15   \n",
      "209681  209694        1213731965505291831K15   \n",
      "209682  209695        1213731965505291831K15   \n",
      "209683  209696        1213731965505291831K15   \n",
      "209684  209697        1213731965505291831K15   \n",
      "209685  209698            6241505057249035M6   \n",
      "209686  209699            6241505057249035M6   \n",
      "209687  209700            6241505057249035M6   \n",
      "209688  209701            6241505057249035M6   \n",
      "209689  209702            6241505057249035M6   \n",
      "209690  209703            6241505057249035M6   \n",
      "209691  209704            6241505057249035M6   \n",
      "209692  209705            6241505057249035M6   \n",
      "209693  209706            6241505057249035M6   \n",
      "209694  209707            6241505057249035M6   \n",
      "209695  209708            6241505057249035M6   \n",
      "209696  209709            6241505057249035M6   \n",
      "209697  209710            6241505057249035M6   \n",
      "209698  209711            6241505057249035M6   \n",
      "209699  209712            6241505057249035M6   \n",
      "\n",
      "                                                  Answers Class Subclass  \n",
      "0       ignoranz den anderen gegenüber.schlecht.die Pe...     M        5  \n",
      "1       mitlachen, mit eingeschlossen zu werden.sie la...     A        5  \n",
      "2       den anderen Umamen, ehrlichkeit, vertrauen.gut...     A        1  \n",
      "3       Sie hält die andere Person, stütz sie. Gut.Sie...     M        1  \n",
      "4       Entspannung, Spaß zu haben. Sie albern herum. ...     A        2  \n",
      "5       Sie unterhalten sich über Dinge, die die die d...     0        0  \n",
      "6       Sie redet aktiv auf die zweite Person ein. übe...     M        4  \n",
      "7       Ruhe zu haben, sie denkt nach.nachdenklich.Sie...     0        0  \n",
      "8       Halt zu kriegen, nach oben zu kommen, Sie klet...     L        3  \n",
      "9       Der zweiten Person zu helfen die \"Kopfnuss\" zu...     M        1  \n",
      "10      Sie beurteilt ein Arbeitsergebnis.mächtig, kon...     M        3  \n",
      "11      Sie bauen ein Gerät zusammen. Wichtig ist die ...     0        0  \n",
      "12      Der zweiten Person zu erklären das Sie einen F...     M        4  \n",
      "13      Der zweite Person Anerkennung zu zeigen..stolz...     M        2  \n",
      "14      Sie hebnt ein großes Gewicht und fühlt sich al...     M        2  \n",
      "15      Der anderen Person seine Ergbenisse zu erläute...     L        2  \n",
      "16      Sie gibt der Gruppe Anweisungen. Wichtig ist I...     M        3  \n",
      "17      Sie mäßregelt die kleinere Person. Wichtig ist...     M        4  \n",
      "18      sie beschützt.gut.weil sie etwas für den ander...     A        3  \n",
      "19      sie reden miteinander.fröhlich.weil sie mitein...     A        2  \n",
      "20      sie lästern über den dritten.unsicher.weil sie...     A        5  \n",
      "21      sie versucht sich zu verteidigen.wie eingesper...     M        3  \n",
      "22      sie denkt nach. für sie ist es wichtig nachzud...     L        1  \n",
      "23      sie will sich retten.in gefahr.weil sie fast r...     L        5  \n",
      "24      sie will ein rätsel lösen.beschützt.weil der a...     L        3  \n",
      "25      für sie ist wichtig dass das kind mal ein arzt...     A        3  \n",
      "26      sie warten dass sie nach hause dürfen.gelangwe...     L        4  \n",
      "27      sie versucht sich zu verteidigen.wütend.weil s...     L        4  \n",
      "28      sie versucht einen auf lieb zu tun.dem anderen...     M        2  \n",
      "29      die einen klatschen, die anderen sind besorgt,...     L        1  \n",
      "...                                                   ...   ...      ...  \n",
      "209670  Sicherheit geben.Ruhig und ausgeglichen.Nähe z...     A        1  \n",
      "209671  Vertrauen und Interesse aneinander.Entspannt.S...     A        1  \n",
      "209672  Es ist für sie wichtig, worüber die beiden spr...     F        4  \n",
      "209673  Sie möchte mit der anderen Person in Kontakt t...     M        3  \n",
      "209674  Ein Mensch, der sie hält, sie fröstelt und ver...     A        5  \n",
      "209675  Es ist für sie wichtig, sich auf den Weg zu ko...     L        2  \n",
      "209676  Sie beobachtet, wie die andere Person (steht i...     M        1  \n",
      "209677  Es ist wichtig für sie, nicht persönlich angeg...     L        5  \n",
      "209678  Diesen Personen ist es wichtig, zusammen zu ar...     L        2  \n",
      "209679  Ihr ist es wichtig, der anderen Person ein Ohr...     M        1  \n",
      "209680  Sich mit der anderen Person zu verbinden (Kont...     A        1  \n",
      "209681  Es ist ihr wichtig, dass alleine zu stemmen, s...     M        3  \n",
      "209682  Sie braucht etwas Ruhe, schaut aus dem Fenster...     F        3  \n",
      "209683  Es ist ihr wichtig, alles so zu erklären, dass...     M        2  \n",
      "209684  Sie hat etwas Schlimmes oder einen Fehler gema...     F        5  \n",
      "209685  einem Menschen helfen.glücklich.weil sie jeman...     M        1  \n",
      "209686  Freundschaft, sie redet mit anderen.gelassen.w...     A        2  \n",
      "209687  die Personen tuscheln.gut.weil sie über jemand...     F        4  \n",
      "209688  die Person redet hektisch auf den anderen ein....     L        4  \n",
      "209689  er ist traurig.allein gelassen.weil er alleine...     A        5  \n",
      "209690  das sie nicht abstürzt.voller Adrenalin.weil s...     L        3  \n",
      "209691  sie tröstet den anderen.sie fühlt sich gebrauc...     M        1  \n",
      "209692  sie hat etwas falsche gemacht.sie fühlt sich u...     M        5  \n",
      "209693  sie bauen etwas.sie fühlen sich wie einer von ...     L        4  \n",
      "209694  sie fragt was passiert ist.wie der Boss.weil s...     M        4  \n",
      "209695  ich helfe jemand anderem.gut.weil sie jemandem...     M        1  \n",
      "209696  das sie nicht die Kraft verliert.wie Hulk.weil...     F        2  \n",
      "209697  Gelassenheit.entspannt.weil sie für sich Recht...     F        1  \n",
      "209698  Mitglied einer Gruppe zu sein.froh.weil man ni...     A        2  \n",
      "209699  lässt traurig den Kopf hängen.niedergemacht.we...     M        5  \n",
      "\n",
      "[209700 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Load Data to pandas frame vor better visualization\n",
    "import pandas as pd\n",
    "completeData = pd.read_csv('OMTGeschichten1_bearb.txt', sep = \";\",\n",
    "                            names = [\"#\",\"Answers\", \"Class\", \"Subclass\"\n",
    "                                    ]\n",
    "                           )\n",
    "shortnedData = pd.read_csv('OMT_shortned.txt', sep = \";\",\n",
    "                            names = [\"#\",\"Answers\", \"Class\", \"Subclass\"\n",
    "                                    ]\n",
    "                           )\n",
    "\n",
    "print('before cleaning...\\n')\n",
    "print(completeData.info(), \"\\n\")\n",
    "print(completeData[\"Class\"].value_counts(), \"\\n\")\n",
    "#delete eventually empty entries\n",
    "completeData = completeData.dropna(axis = 0)\n",
    "shortnedData = shortnedData.dropna(axis = 0)\n",
    "\n",
    "#delete eventually wrong labels ('\\N' seems to accure from time to time)\n",
    "completeData = completeData.drop(completeData[completeData.Class == '\\\\N'].index).reset_index()\n",
    "shortnedData = shortnedData.drop(shortnedData[shortnedData.Class == '\\\\N'].index).reset_index()\n",
    "print('after cleaning...\\n')\n",
    "print(completeData.info())\n",
    "print(completeData[\"Class\"].value_counts(), \"\\n\")\n",
    "print(completeData.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infos from X_train... \n",
      "\n",
      "\n",
      "count                                      188730\n",
      "unique                                     188524\n",
      "top       keine ahnung.keine ahnung.keine ahnung.\n",
      "freq                                           10\n",
      "Name: Answers, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Infos from X_test... \n",
      "\n",
      "\n",
      "count                               20970\n",
      "unique                              20968\n",
      "top       ruhe.unter druck.andere person.\n",
      "freq                                    2\n",
      "Name: Answers, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the needed infos from data_complete\n",
    "data = completeData.filter([\"Answers\", \"Class\"],axis = 1)\n",
    "dataShortned = shortnedData.filter([\"Answers\", \"Class\"],axis = 1)\n",
    "\n",
    "#Motive F is basicly a sub-motive from M and therefore not further used as indipendent motive\n",
    "data[\"Class\"] = data[\"Class\"].replace([\"F\"],[\"M\"])\n",
    "dataShortned[\"class\"] = dataShortned[\"Class\"].replace([\"F\"], [\"M\"])\n",
    "#split it into X ( = input) and y ( the labels)\n",
    "X, y = data[\"Answers\"], data[\"Class\"]\n",
    "XShortned, yShortned = dataShortned[\"Answers\"], dataShortned[\"Class\"]\n",
    "\n",
    "#split data into train and test set, stratified and a 90:10 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.1, stratify = y)\n",
    "X_train_shortned, X_test_shortned, y_train_shortned, y_test_shortned = train_test_split(XShortned, yShortned , test_size = 0.2, random_state = 42,)\n",
    "\n",
    "print('Infos from X_train... \\n\\n')\n",
    "print(X_train.describe())\n",
    "print('\\n\\n\\n')\n",
    "print('Infos from X_test... \\n\\n')\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Der', 'Trainer', 'der', 'Fußballmannschaft', 'erklärt', 'den', 'Spielern', 'die', 'Taktik', 'für', 'das', 'nächste', 'Spiel', ',', 'ihm', 'ist', 'wichtig', ',', 'dass', 'alle', 'zuhören', '.', 'die', 'Person', 'fühlt', 'sich', 'als', 'Fußballlehrer', 'und', 'als', 'derjenige', ',', 'der', 'den', 'Jungs', 'etwas', 'beibringen', 'möchte', '.', 'er', 'wahrt', 'die', 'Distanz', ',', 'macht', 'den', 'Unterschied', 'zu', 'den', 'Jungs', ',', 'fühlt', 'sich', 'aber', 'für', 'sie', 'verantwortlich', '.'], ['Sie', 'möchte', 'ihre', 'persönliche', 'Meinung', 'gegnüber', 'den', 'Anhängern', 'einer', 'bestimmten', 'politischen', 'Partei', 'zum', 'Ausdruck', 'bringen', 'und', 'begibt', 'sich', 'deshalb', 'zu', 'einem', 'Parteitag', 'dieser', 'Partei', '.', 'Sie', 'fühlt', 'sich', 'gekränkt', 'von', 'dem', 'Parteiprogramm', 'der', 'Partei', 'und', 'ist', 'selbstbewusst', 'bei', 'der', 'Sache', ',', 'wenn', 'es', 'darum', 'geht', ',', 'die', 'eigene', 'Meinung', 'zu', 'äußern', '.', 'Die', 'Partei', 'möchte', 'die', 'Presse-', 'und', 'Meinungsfreiheit', 'einschränken', '.', 'Die', 'Person', 'bringt', 'ihre', 'Auffassung', 'besonders', 'gut', 'zum', 'Ausdruck', 'und', 'verlässt', 'den', 'Veranstaltungsort', 'züguig', 'wieder', 'und', 'es', 'verbleiben', 'nachdenkliche', 'Ges'], ['beschützt', 'zu', 'werden', 'und', 'Zuneigung', 'zu', 'erfahren', '.', 'geborgen', ',', 'geliebt', '.', 'Weil', 'man', 'sie', 'in', 'den', 'Arm', 'nimmt', '.'], ['Sie', 'möchten', 'den', 'Gegenstand', 'auffangen', '.', 'Sie', 'sind', 'konzentriert', '.', 'Weil', 'sie', 'ein', 'konkretes', 'Ziel', 'vor', 'Augen', 'haben', '.'], ['sie', 'steht', 'stämmig', 'neben', 'der', 'anderen', '.', 'nicht', 'gut', '.', 'die', 'andere', 'hat', 'wohl', 'was', 'falsch', 'gemacht', '.']]\n",
      "[['Dass', 'der', 'Vater', 'ihm', 'zuhört', '.', 'Erklärt', 'die', 'Situation', 'und', 'wartet', 'auf', 'die', 'Reaktion', 'seines', 'Vaters', '.', 'enttäuscht', ',', 'hoffnungsvoll', ',', 'dass', 'er', 'Unterstützung', 'bekommen', 'wird', '.', 'Er', 'weiss', ',', 'dass', 'er', 'sich', 'daneben', 'benommen', 'hat', 'in', 'der', 'Schule', '.', 'Er', 'wünscht', 'sich', 'trotzdem', ',', 'dass', 'sein', 'Vater', 'ihm', 'vergibt', '.', 'Der', 'Vater', 'schickt', 'ihn', 'früh', 'ins', 'Bett', '.', 'Er', 'muss', 'zuerst', 'die', 'Situation', 'mit', 'der', 'Mutter', 'besprechen..'], ['Zuhören', ',', 'da', 'sein', ',', 'stärken', ',', 'fordern', ',', 'klären', ',', 'unterstützen', '.', 'stark', ',', 'klar', ',', 'bestimmend', ',', 'in', 'Verbindung', ',', 'verbunden', ',', 'ergänzt', 'durch', 'sein', 'Visavis', '.', 'sie', 'steht', 'stabil', ',', 'hat', 'eine', 'offene', 'Haltung', 'und', 'ist', 'aktiv', 'im', 'Klärungsprozess', '.', 'Sabine', 'und', 'Franz-Josef', '(', 'Hauptperson', ')', 'hatten', 'eine', 'Auseinandersetzung', '.', 'Jetzt', 'versöhnen', 'sie', 'sich', '.', 'Er', 'gibt', 'seinem', 'Standpunkt', 'Nachdruck', '.'], ['die', 'person', 'unterhält', 'sich', 'und', 'bietet', 'ihre', 'hand', 'an', ',', 'um', 'der', 'anderen', 'person', 'nahe', 'zu', 'sein', '.', 'abgewiesen', 'und', 'traurig', '.', 'weil', 'die', 'andere', 'person', 'sich', 'diatnziert', '.', 'die', 'geschichte', 'wiederholt', 'sich', ',', 'aber', 'die', 'andere', 'person', 'lässt', 'immer', 'wieder', 'nähe', 'zu', '.']]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "# The pattern I may don't want in my corpus \n",
    "pattern = re.compile(\"\\-|\\!|\\:|\\.|\\d|\\,|\\:|\\(|\\)|\\?|\\\"|\\\\|\\+|\\%|\\/\")\n",
    "def remove_patterns_from_string(strg):\n",
    "    return re.sub(pattern, \" \", strg)\n",
    "\n",
    "# transforms pattern like xyz.Abc to xyz. Abc (--> helps tokenizer to detect sentences)\n",
    "def insert_space_between_special_chars(strg):\n",
    "    return re.sub('([a-zA-Z])([^A-Za-z0-9]+)([a-zA-Z])', r'\\1\\2 \\3', strg)\n",
    "\n",
    "# german stopwords (words who accure very often in texts and don't contribute anything to the text like articles, conjunctions)\n",
    "stopWords = set(stopwords.words(\"german\"))\n",
    "\n",
    "#new spellings\n",
    "stopWords.add('dass')\n",
    "\n",
    "#tokenizes a list of strings\n",
    "#return: list of tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text, language = 'german')\n",
    "    return tokens\n",
    "\n",
    "#retrns: list of strings which do not occure in stopWords\n",
    "def remove_stopwords(text):\n",
    "    return [w for w in text if not w in stopWords]\n",
    "\n",
    "# in : row for row from vector\n",
    "# out: preprocessed version of the row\n",
    "def preprocess_text(corpus):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "#to change xyz.abc to xyz. abc\n",
    "        text = re.sub('([a-zA-Z])(\\.)([a-zA-Z])', r'\\1\\2 \\3', text)\n",
    "        #text = text.lower()\n",
    "        #text = remove_patterns_from_string(text)\n",
    "        text = tokenize_text(text)\n",
    "        #text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "    return normalized_corpus\n",
    "\n",
    "#preprocess only X_train. X_test gets its own pipeline in the end\n",
    "X_train_preprocessed = preprocess_text(X_train)\n",
    "X_train_shortned_preprocessed = preprocess_text(X_train_shortned)\n",
    "print(X_train_preprocessed[:5])\n",
    "print(X_train_shortned_preprocessed[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       992\n",
      "           A       0.00      0.00      0.00      3538\n",
      "           L       0.00      0.00      0.00      4096\n",
      "           M       0.59      1.00      0.74     12344\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     20970\n",
      "   macro avg       0.15      0.25      0.19     20970\n",
      "weighted avg       0.35      0.59      0.44     20970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# minimal classification performance: all answers set to M ( ZeroN - Classifier)\n",
    "m_labels = []\n",
    "for i in range(len(y_test)):\n",
    "    m_labels.append(\"M\")\n",
    "machtmotiv = pd.Series(m_labels)\n",
    "print(classification_report(y_test, machtmotiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first classification on complete data; \n",
    "#using params, which seems best based on sample-sized classification with 1000 examples\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import clone\n",
    "\n",
    "#for every fold, split first into new stratified train/dev set\n",
    "    # vectorizer && classifier must implement the conditions of sklearns pipeline \n",
    "    #vectorizer must implement fit transform\n",
    "    #classifier must implement fit\n",
    "    \n",
    "def kfold_f1_classification(vectorizer, classifier, trainingData, trainingLabel, folds=3):\n",
    "    t0 = time()\n",
    "    print('starting classification...')\n",
    "    for j in range(folds):\n",
    "        XTrain, XDev, yTrain, yDev = [],[],[],[]\n",
    "        pipeline = []\n",
    "        #split into 90:10 train test sets\n",
    "        XTrain, XDev, yTrain, yDev = train_test_split(trainingData, trainingLabel, test_size= 0.1, stratify = y_train)\n",
    "        pipeline = Pipeline([\n",
    "            ('vect1', clone(vectorizer)),\n",
    "                            \n",
    "            ('clf', clone(classifier)),    \n",
    "        ])\n",
    "        pipeline.fit(XTrain, yTrain)\n",
    "        predictions = pipeline.predict(XDev)\n",
    "        print(\"classification \", j)\n",
    "        print(classification_report(yDev, predictions))\n",
    "        print()\n",
    "        print()\n",
    "    return(\"done in %0.3fs\" % (time()-t0))\n",
    "\n",
    "\n",
    "def kfold_f1_classification_pipe(pipe, classifier, trainingData, trainingLabel, folds=3):\n",
    "    t0 = time()\n",
    "    print('starting classification...')\n",
    "    for j in range(folds):\n",
    "        XTrain, XDev, yTrain, yDev = [],[],[],[]\n",
    "        pipeline = []\n",
    "        \n",
    "        XTrain, XDev, yTrain, yDev = train_test_split(trainingData, trainingLabel, test_size= 0.1, stratify = y_train)\n",
    "        pipeline = Pipeline([\n",
    "            ('pipe', pipe),\n",
    "                            \n",
    "            ('clf', clone(classifier)),    \n",
    "        ])\n",
    "        pipeline.fit(XTrain, yTrain)\n",
    "        predictions = pipeline.predict(XDev)\n",
    "        print(\"classification \", j)\n",
    "        print(classification_report(yDev, predictions))\n",
    "        print()\n",
    "        print()\n",
    "    return(\"done in %0.3fs\" % (time()-t0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here starts the first experiment trying to evaluate the OMT only by its answers with ML. \n",
    "Features are only the word occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.22      0.31       893\n",
      "           A       0.80      0.75      0.78      3185\n",
      "           L       0.81      0.76      0.78      3686\n",
      "           M       0.84      0.91      0.88     11109\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     18873\n",
      "   macro avg       0.74      0.66      0.68     18873\n",
      "weighted avg       0.81      0.82      0.81     18873\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.21      0.30       893\n",
      "           A       0.79      0.75      0.77      3185\n",
      "           L       0.81      0.76      0.78      3686\n",
      "           M       0.84      0.91      0.87     11109\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     18873\n",
      "   macro avg       0.73      0.66      0.68     18873\n",
      "weighted avg       0.81      0.82      0.81     18873\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.23      0.32       893\n",
      "           A       0.81      0.75      0.78      3185\n",
      "           L       0.80      0.76      0.78      3686\n",
      "           M       0.84      0.91      0.87     11109\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     18873\n",
      "   macro avg       0.74      0.66      0.69     18873\n",
      "weighted avg       0.81      0.82      0.81     18873\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done in 542.204s'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_f1_classification(vectorizer =CountVectorizer(ngram_range=(1,1),\n",
    "                                                    preprocessor = my_dummy,\n",
    "                                                    tokenizer =my_dummy, \n",
    "                                                    token_pattern=None,\n",
    "                                                    max_features = 10000),\n",
    "                        classifier =LinearSVC(C = 1, max_iter = 2000),\n",
    "                        trainingData= X_train_preprocessed,\n",
    "                        trainingLabel= y_train)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classification with KNN and LDA - Features...\n",
      "performing gridsearch...\n",
      "pipeline: ['pipeLDA', 'svm']\n",
      "parameters:\n",
      "{'pipeLDA__vect_lda__max_df': (0.9,), 'pipeLDA__vect_lda__min_df': (10,), 'pipeLDA__vect_lda__ngram_range': ((1, 1),), 'pipeLDA__vect_lda__max_features': (3000,), 'pipeLDA__lda__n_components': (10, 50, 100)}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed: 17.1min remaining: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 24.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2032.057s\n",
      "\n",
      "Best score: 0.765\n",
      "best parameters set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.03      0.05       893\n",
      "           A       0.75      0.59      0.66      3185\n",
      "           L       0.81      0.66      0.72      3686\n",
      "           M       0.77      0.93      0.84     11109\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     18873\n",
      "   macro avg       0.79      0.55      0.57     18873\n",
      "weighted avg       0.78      0.78      0.75     18873\n",
      "\n",
      "\tpipeLDA__lda__n_components: 100\n",
      "\tpipeLDA__vect_lda__max_df: 0.9\n",
      "\tpipeLDA__vect_lda__max_features: 3000\n",
      "\tpipeLDA__vect_lda__min_df: 10\n",
      "\tpipeLDA__vect_lda__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Only use LDA with different number of topics and SVM classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn. decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"start classification with LDA - Features...\")\n",
    "#define pipeline combining feature extractor with classifier\n",
    "pipelineLdaKnn = Pipeline([\n",
    "    ('pipeLDA', Pipeline([\n",
    "                                  ('vect_lda', CountVectorizer(preprocessor = my_dummy,\n",
    "                                                               tokenizer =my_dummy, token_pattern=None)),\n",
    "                                   ('lda', LatentDirichletAllocation(learning_method = 'batch'))\n",
    "                              ])),\n",
    "                            \n",
    "    ('svm', LinearSVC(max_iter=1000)),    \n",
    "])\n",
    "\n",
    "parametersLdaKnn = {\n",
    "    'pipeLDA__vect_lda__max_df': (0.9,),\n",
    "    'pipeLDA__vect_lda__min_df': (10,),\n",
    "    'pipeLDA__vect_lda__ngram_range':((1,1),),\n",
    "    'pipeLDA__vect_lda__max_features': (3000,),\n",
    "    'pipeLDA__lda__n_components': (10, 50,100,),\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #find best params for this feature extraction methods\n",
    "    gridSearchLdaKnn = GridSearchCV(pipelineLdaKnn, parametersLdaKnn, cv=3,\n",
    "                           n_jobs = -1, verbose = 1)\n",
    "    print(\"performing gridsearch...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipelineLdaKnn.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parametersLdaKnn)\n",
    "    time_svc = time()\n",
    "    \n",
    "    XTrainHelp, XDevHelp, yTrainHelp, yDevHelp = train_test_split(X_train_preprocessed, y_train, test_size= 0.1, stratify = y_train)\n",
    "    gridSearchLdaKnn.fit(XTrainHelp, yTrainHelp)\n",
    "    print(\"done in %0.3fs\" % (time()-time_svc))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gridSearchLdaKnn.best_score_)\n",
    "    print(\"best parameters set:\")\n",
    "    best_parameters = gridSearchLdaKnn.best_estimator_.get_params()\n",
    "    XDevHelpPredicted = gridSearchLdaKnn.predict(XDevHelp)\n",
    "    \n",
    "    print(classification_report(yDevHelp, XDevHelpPredicted))\n",
    "    \n",
    "    for param_name in sorted(parametersLdaKnn.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classification with SVM, BOW and LDA - Features...\n",
      "performing gridsearch...\n",
      "pipeline: ['union', 'svm']\n",
      "parameters:\n",
      "{}\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed: 13.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed: 13.5min finished\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2395.970s\n",
      "\n",
      "Best score: 0.815\n",
      "best parameters set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.34       893\n",
      "           A       0.78      0.74      0.76      3185\n",
      "           L       0.81      0.75      0.78      3686\n",
      "           M       0.84      0.91      0.87     11109\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     18873\n",
      "   macro avg       0.76      0.66      0.69     18873\n",
      "weighted avg       0.81      0.82      0.81     18873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn. decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"start classification with SVM, BOW and LDA - Features...\")\n",
    "#define pipeline combining feature extractor with classifier\n",
    "pipelineBowLDA = Pipeline([\n",
    "    ('union', FeatureUnion(transformer_list = [\n",
    "                                        ('vect3', CountVectorizer(preprocessor = my_dummy,\n",
    "                                                                  tokenizer =my_dummy, \n",
    "                                                                  token_pattern=None,\n",
    "                                                                  max_features = 5000)),           \n",
    "                                  \n",
    "                                        ('pipe2', Pipeline([\n",
    "                                              \n",
    "                                            ('vect_lda', CountVectorizer(\n",
    "                                                                preprocessor = my_dummy,\n",
    "                                                                tokenizer =my_dummy, \n",
    "                                                                token_pattern=None,\n",
    "                                                                max_features = 5000\n",
    "                                                                        )),\n",
    "                                            ('lda1', LatentDirichletAllocation(\n",
    "                                                                               learning_method = 'batch',\n",
    "                                                                               n_components = 250\n",
    "                                                                               \n",
    "                                                                      ))\n",
    "                              ]))\n",
    "                            ])),\n",
    "                            \n",
    "    ('svm', LinearSVC(max_iter=2000)),    \n",
    "])\n",
    "\n",
    "parametersLdaKnn = {}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #find best params for this feature extraction methods\n",
    "    gridSearchBowLdaSVM = GridSearchCV(pipelineBowLDA, parametersLdaKnn, cv=2,\n",
    "                           n_jobs = -1, verbose = 1)\n",
    "    print(\"performing gridsearch...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipelineBowLDA.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parametersLdaKnn)\n",
    "    time_svc = time()\n",
    "    \n",
    "    XTrainHelp, XDevHelp, yTrainHelp, yDevHelp = train_test_split(X_train_preprocessed, y_train, test_size= 0.1, stratify = y_train)\n",
    "    gridSearchBowLdaSVM.fit(XTrainHelp, yTrainHelp)\n",
    "    print(\"done in %0.3fs\" % (time()-time_svc))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gridSearchBowLdaSVM.best_score_)\n",
    "    print(\"best parameters set:\")\n",
    "    best_parameters = gridSearchBowLdaSVM.best_estimator_.get_params()\n",
    "    XDevHelpPredicted = gridSearchBowLdaSVM.predict(XDevHelp)\n",
    "    \n",
    "    print(classification_report(yDevHelp, XDevHelpPredicted))\n",
    "    \n",
    "    for param_name in sorted(parametersLdaKnn.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
