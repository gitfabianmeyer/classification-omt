{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Algorithmus:\n",
    "    1. Initalize parameters\n",
    "    2. For each document, randomly initialize earch word to one of the k topics\n",
    "    3. start an iterative process as follows and repeat it X times.\n",
    "    4. For each document D:\n",
    "        a. For each word W in document\n",
    "            - for each topic t :\n",
    "                Compute P(T|D), which ist proportion of wirds in D assigned to topic T\n",
    "                Compute P(W|T) which is proportion of assignements to topic T over all documents having word W\n",
    "            - Reassign  W with  T with probability P(T|D) x P(W|T) considering all other words and their topic assignements\n",
    "\n",
    "\n",
    "To Do: \n",
    "    Text vorbereiten: \n",
    "        ideen prüfen: Alle antworten eines Kandidaten zusammenfassen, einnzeln testen, labels dalassen / entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk, codecs\n",
    "from nltk import word_tokenize\n",
    "from time import time\n",
    "t0 = time()\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.008s.\n",
      "Länge omt_matrix:  1000 \n",
      " omt_matrix[10][1]:  Sie beurteilt ein Arbeitsergebnis.mächtig, kontrollierend, unabhängig.Sie trägt die Verantwortung und Entscheidung..Nach der Kontrolle wird das Arbeitsergebnis modifiziert und die zweite Person führt die besprochenen weiteren Arbeitsschritte aus. \n",
      "omt_matrix[10]:  ['52122529750377312346781011', 'Sie beurteilt ein Arbeitsergebnis.mächtig, kontrollierend, unabhängig.Sie trägt die Verantwortung und Entscheidung..Nach der Kontrolle wird das Arbeitsergebnis modifiziert und die zweite Person führt die besprochenen weiteren Arbeitsschritte aus. ', 'M', '3\\n']\n",
      "type omt_matrix:  <class 'list'>\n",
      "type omt_matrix[10]:  <class 'list'>\n",
      "type omt_matrix[10][1] <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Daten in Matrix einlesen, matrix[1] ist Text\n",
    "# STANDART PYTHON METHODE\n",
    "import numpy as np\n",
    "import csv\n",
    "from time import time\n",
    "t1 = time()\n",
    "omt_matrix = []\n",
    "with open('omt_shortned.txt', encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        omt_matrix.append(line.split(\";\"))\n",
    "print(\"done in %0.3fs.\" % (time() - t1))\n",
    "\n",
    "print(\"Länge omt_matrix: \",len(omt_matrix), \"\\n\", \"omt_matrix[10][1]: \",omt_matrix[10][1])\n",
    "print(\"omt_matrix[10]: \",omt_matrix[10])\n",
    "print(\"type omt_matrix: \",type(omt_matrix))\n",
    "print(\"type omt_matrix[10]: \",type(omt_matrix[10]))\n",
    "print(\"type omt_matrix[10][1]\", type(omt_matrix[10][1]))\n",
    "\n",
    "\n",
    "t2= time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      "#           1000 non-null object\n",
      "Answers     1000 non-null object\n",
      "Class       1000 non-null object\n",
      "Subclass    1000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.3+ KB\n",
      "None \n",
      "\n",
      "M     518\n",
      "L     194\n",
      "A     192\n",
      "0      91\n",
      "\\N      5\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      "#           1000 non-null object\n",
      "Answers     1000 non-null object\n",
      "Class       1000 non-null object\n",
      "Subclass    1000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Load Data to pandas - frame vor better visualization\n",
    "import pandas as pd\n",
    "complete_data = pd.read_csv('omt_shortned.txt', sep = \";\",\n",
    "                           names = [\"#\",\"Answers\", \"Class\" , \"Subclass\"] )\n",
    "\n",
    "print(complete_data.info(), \"\\n\")\n",
    "print(complete_data[\"Class\"].value_counts(), \"\\n\")\n",
    "complete_data.dropna(axis = 0)\n",
    "print(complete_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract important infos from data_complete\n",
    "data = complete_data.filter([\"Answers\", \"Class\"],axis = 1)\n",
    "\n",
    "#split it into X ( = input) and y ( the labels)\n",
    "X, y = data[\"Answers\"], data[\"Class\"]\n",
    "\n",
    "#split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.15, random_state = 42)\n",
    "\n",
    "# Print Samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'A', 'L', 'M', '\\\\N'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# The pattern I don't want in my corpus  (TO DO: \"+\" taucht noch im Text auf)\n",
    "pattern = re.compile(\"\\-|\\!|\\:|\\.|\\d|\\,|\\:|\\(|\\)|\\?|\\\"|\\\\|\\+|\\%|\\/\")\n",
    "\n",
    "#return: a patternless copy of the input string\n",
    "def remove_patterns_from_string(strg):\n",
    "    return re.sub(pattern, \" \", strg)\n",
    "\n",
    "# german stopwords ( words who accure very often in texts and don't contribute anything to the text like articles, conjunctions)\n",
    "stopWords = set(stopwords.words(\"german\"))\n",
    "stopWords.add('dass')\n",
    "\n",
    "#tokenizes a list of strings\n",
    "#return: list of tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text, language = 'german')\n",
    "    return tokens\n",
    "\n",
    "#retrns: list of strings which do not occure in stopWords\n",
    "def remove_stopwords(text):\n",
    "    return [w for w in text if not w in stopWords]\n",
    "\n",
    "# in : row for row from vector\n",
    "# out: preprocessed version of the row\n",
    "def preprocess_text(corpus):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = remove_patterns_from_string(text.lower())\n",
    "        text = tokenize_text(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "    return normalized_corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocess_text(X_train)\n",
    "X_test_preprocessed = preprocess_text(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def my_dummy(doc):\n",
    "    return doc\n",
    "\n",
    "\n",
    "def built_bow(corpus, ngram_range =(1,1)):\n",
    "    vectorizer = CountVectorizer(ngram_range = ngram_range,\n",
    "                                analyzer = 'word', tokenizer = my_dummy,\n",
    "                                 preprocessor = my_dummy, token_pattern = None,\n",
    "                                 min_df = 2, max_df=0.9)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "def show_features(features, feature_names):\n",
    "    df = pd.DataFrame(data= features, columns = feature_names)\n",
    "    print(df)\n",
    "\n",
    "bow_vectorizer, bow_train_features = built_bow(X_train_preprocessed)\n",
    "features_bow_pd = bow_train_features.todense()\n",
    "feature_names_bow = bow_vectorizer.get_feature_names()\n",
    "\n",
    "bow_test_features = bow_vectorizer.transform(X_test_preprocessed)\n",
    "#show_features(features_bow_pd, feature_names_bow )\n",
    "# print(feature_names_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "#smooth: verhindert 0 - Division\n",
    "#norm l2\n",
    "#nutzt rohe Daten statt bow-vorarbeit\n",
    "def tfidf_vectorizer(raw_data, ngram_range=(1,1)):\n",
    "    vectorizer = TfidfVectorizer(norm = 'l2', smooth_idf = True, use_idf = True, ngram_range = ngram_range, \n",
    "                                 analyzer = 'word', tokenizer = my_dummy,\n",
    "                                 preprocessor = my_dummy, token_pattern = None,\n",
    "                                 min_df = 2, max_df=0.9)\n",
    "    tfidf_matrix = vectorizer.fit_transform(raw_data)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "tfidf, tfidf_train_features = tfidf_vectorizer(X_train_preprocessed)\n",
    "tfidf_features_round = np.round(tfidf_train_features.todense(), 2)\n",
    "\n",
    "tfidf_test_features = tfidf.transform(X_test_preprocessed)\n",
    "\n",
    "#show_features(tfidf_features_round, feature_names_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing:\n",
    "    Tokenization (Jede Zeile soll hinterher ein Doc sein\n",
    "    stop words entfernen\n",
    "    ggf: antworten einer Person sammeln, Labels entfernen, Labels durch \"gesamtlabel\" ersetzen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy: ', np.round(metrics.accuracy_score(true_labels, predicted_labels),2))\n",
    "    print('Precision: ', np.round(metrics.precision_score(true_labels, predicted_labels, average = 'weighted'),2))\n",
    "    print('Recall: ', np.round(metrics.recall_score(true_labels, predicted_labels, average = 'weighted'),2))\n",
    "    print('F1 Score: ', np.round(metrics.f1_score(true_labels, predicted_labels, average= 'weighted'),2))\n",
    "    \n",
    "def train_predict_evaluate_model(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    #build model\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    #prediction with my model\n",
    "    predictions = classifier.predict(test_features)\n",
    "    #evaluate\n",
    "    calculate_metrics(true_labels = test_labels, predicted_labels = predictions)\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "m_labels = []\n",
    "for i in range(150):\n",
    "    m_labels.append(\"M\")\n",
    "machtmotiv = pd.Series(m_labels)\n",
    "\n",
    "print(type(machtmotiv))\n",
    "\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MNB; BOW; Y_test only M\n",
      "Accuracy:  0.62\n",
      "Precision:  1.0\n",
      "Recall:  0.62\n",
      "F1 Score:  0.77\n",
      "\n",
      "Multinomial Naive Bayes with bag of words Model\n",
      "Accuracy:  0.74\n",
      "Precision:  0.77\n",
      "Recall:  0.74\n",
      "F1 Score:  0.72\n",
      "\n",
      "Multinomial Naive Bayes with tfidf Model\n",
      "Accuracy:  0.66\n",
      "Precision:  0.7\n",
      "Recall:  0.66\n",
      "F1 Score:  0.61\n",
      "\n",
      "SVM with bag of words Model\n",
      "Accuracy:  0.65\n",
      "Precision:  0.63\n",
      "Recall:  0.65\n",
      "F1 Score:  0.63\n",
      "\n",
      "svm with tfidf Model\n",
      "Accuracy:  0.66\n",
      "Precision:  0.66\n",
      "Recall:  0.66\n",
      "F1 Score:  0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "multinomial_nb = MultinomialNB()\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)\n",
    "\n",
    "print('\\n MNB; BOW; Y_test only M')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=multinomial_nb, \n",
    "                                                   train_features =bow_train_features,\n",
    "                                                   train_labels = y_train,\n",
    "                                                    test_features = bow_test_features,\n",
    "                                                    test_labels = machtmotiv)\n",
    "# mnb with BOW\n",
    "print('\\nMultinomial Naive Bayes with bag of words Model')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=multinomial_nb, \n",
    "                                                   train_features =bow_train_features,\n",
    "                                                   train_labels = y_train,\n",
    "                                                    test_features = bow_test_features,\n",
    "                                                    test_labels = y_test)\n",
    "print('\\nMultinomial Naive Bayes with tfidf Model')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=multinomial_nb, \n",
    "                                                   train_features =tfidf_train_features,\n",
    "                                                   train_labels = y_train,\n",
    "                                                    test_features = tfidf_test_features,\n",
    "                                                    test_labels = y_test)\n",
    "\n",
    "print('\\nSVM with bag of words Model')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=svm, \n",
    "                                                   train_features =bow_train_features,\n",
    "                                                   train_labels = y_train,\n",
    "                                                    test_features = bow_test_features,\n",
    "                                                    test_labels = y_test)\n",
    "\n",
    "print('\\nsvm with tfidf Model')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=svm, \n",
    "                                                   train_features =tfidf_train_features,\n",
    "                                                   train_labels = y_train,\n",
    "                                                    test_features = tfidf_test_features,\n",
    "                                                    test_labels = y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=100, mean_change_tol=0.001,\n",
       "             n_components=4, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topics = 4\n",
    "lda = LatentDirichletAllocation(n_components = total_topics, \n",
    "                                max_iter = 100, learning_method = 'online', \n",
    "                                learning_offset=50., random_state = 42)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('gut', 90.12), ('person', 79.83), ('arbeit', 64.01), ('zusammen', 63.72), ('aufgabe', 53.59), ('wichtig', 53.03), ('berg', 48.97), ('gehen', 47.94), ('lösen', 46.37), ('stolz', 40.43)]\n",
      "Topic #2 with weights\n",
      "[('person', 571.01), ('wichtig', 125.71), ('fühlt', 98.74), ('kind', 95.37), ('möchte', 92.13), ('beiden', 80.84), ('gut', 75.82), ('geht', 72.06), ('gruppe', 51.56), ('situation', 49.48)]\n",
      "Topic #3 with weights\n",
      "[('person', 59.91), ('bekommt', 40.17), ('lösung', 33.22), ('problem', 31.68), ('hp', 26.99), ('steht', 26.53), ('finden', 22.05), ('helfen', 20.13), ('ängstlich', 18.17), ('ärger', 16.95)]\n",
      "Topic #4 with weights\n",
      "[('schüler', 24.27), ('stein', 24.08), ('lehrer', 19.2), ('stark', 18.57), ('mal', 17.88), ('nie', 17.64), ('lässt', 15.23), ('enttäuscht', 12.33), ('stolz', 12.26), ('geschafft', 11.81)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_topics_terms_weights(weights, feature_names):\n",
    "    feature_names = np.array(feature_names)\n",
    "    sorted_indices = np.array([list(row[::-1])\n",
    "                              for row\n",
    "                              in np.argsort(np.abs(weights))])\n",
    "    sorted_weights = np.array([list(wt[index])\n",
    "                              for wt, index\n",
    "                              in zip(weights, sorted_indices)])\n",
    "    sorted_terms = np.array([list(feature_names[row])\n",
    "                            for row\n",
    "                            in sorted_indices])\n",
    "    topics = [np.vstack((terms.T,\n",
    "                        term_weights.T)).T\n",
    "             for terms, term_weights\n",
    "             in zip(sorted_terms, sorted_weights)]\n",
    "    return topics\n",
    "#auf jeden fall quelle des codes raussuchen\n",
    "\n",
    "\n",
    "def print_topics_udf(topics, total_topics = 1,\n",
    "                    weight_threshold = 0.0001,\n",
    "                    display_weights = False,\n",
    "                    num_terms=None):\n",
    "    for index in range(total_topics):\n",
    "        topic = topics[index]\n",
    "        topic = [(term, float(wt))\n",
    "                for term, wt in topic]\n",
    "        topic = [(word, round(wt, 2))\n",
    "                for word, wt in topic\n",
    "                if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print('Topic #' + str(index+1) + ' with without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print\n",
    "        \n",
    "\n",
    "# get terms and their weights\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "weights = lda.components_\n",
    "\n",
    "# generate topics from their terms and weights\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics = topics,\n",
    "                total_topics = total_topics,\n",
    "                num_terms=10,\n",
    "                display_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.776s.\n"
     ]
    }
   ],
   "source": [
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
