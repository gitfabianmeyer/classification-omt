{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk, codecs\n",
    "from nltk import word_tokenize\n",
    "from time import time\n",
    "import sys\n",
    "t0 = time()\n",
    "\n",
    "# to use my own preprocessing in the vectorizer later\n",
    "def my_dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      "#           1000 non-null object\n",
      "Answers     1000 non-null object\n",
      "Class       1000 non-null object\n",
      "Subclass    1000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.3+ KB\n",
      "None \n",
      "\n",
      "M     518\n",
      "L     194\n",
      "A     192\n",
      "0      91\n",
      "\\N      5\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "after cleaning...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 995 entries, 0 to 994\n",
      "Data columns (total 5 columns):\n",
      "index       995 non-null int64\n",
      "#           995 non-null object\n",
      "Answers     995 non-null object\n",
      "Class       995 non-null object\n",
      "Subclass    995 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.9+ KB\n",
      "None\n",
      "M    518\n",
      "L    194\n",
      "A    192\n",
      "0     91\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "<bound method NDFrame.head of      index                               #  \\\n",
      "0        0        185124138106620081063215   \n",
      "1        1        185124138106620081063215   \n",
      "2        2        185124138106620081063215   \n",
      "3        3      52122529750377312346781011   \n",
      "4        4      52122529750377312346781011   \n",
      "5        5      52122529750377312346781011   \n",
      "6        6      52122529750377312346781011   \n",
      "7        7      52122529750377312346781011   \n",
      "8        8      52122529750377312346781011   \n",
      "9        9      52122529750377312346781011   \n",
      "10      10      52122529750377312346781011   \n",
      "11      11      52122529750377312346781011   \n",
      "12      12      52122529750377312346781011   \n",
      "13      13      52122529750377312346781011   \n",
      "14      14      52122529750377312346781011   \n",
      "15      15      52122529750377312346781011   \n",
      "16      16      52122529750377312346781011   \n",
      "17      17      52122529750377312346781011   \n",
      "18      18    4812248500709191234567891011   \n",
      "19      19    4812248500709191234567891011   \n",
      "20      20    4812248500709191234567891011   \n",
      "21      21    4812248500709191234567891011   \n",
      "22      22    4812248500709191234567891011   \n",
      "23      23    4812248500709191234567891011   \n",
      "24      24    4812248500709191234567891011   \n",
      "25      25    4812248500709191234567891011   \n",
      "26      26    4812248500709191234567891011   \n",
      "27      27    4812248500709191234567891011   \n",
      "28      28    4812248500709191234567891011   \n",
      "29      29    4812248500709191234567891011   \n",
      "..     ...                             ...   \n",
      "965    970    9012333411730141234567891011   \n",
      "966    971    9012333411730141234567891011   \n",
      "967    972    9012333411730141234567891011   \n",
      "968    973    9012333411730141234567891011   \n",
      "969    974    9012333411730141234567891011   \n",
      "970    975    9012333411730141234567891011   \n",
      "971    976    1001231614795044123456781011   \n",
      "972    977    1001231614795044123456781011   \n",
      "973    978    1001231614795044123456781011   \n",
      "974    979    1001231614795044123456781011   \n",
      "975    980    1001231614795044123456781011   \n",
      "976    981    1001231614795044123456781011   \n",
      "977    982    1001231614795044123456781011   \n",
      "978    983    1001231614795044123456781011   \n",
      "979    984    1001231614795044123456781011   \n",
      "980    985    1001231614795044123456781011   \n",
      "981    986    1001231614795044123456781011   \n",
      "982    987    1001231614795044123456781011   \n",
      "983    988    1001231614795044123456781011   \n",
      "984    989    1001231614795044123456781011   \n",
      "985    990    1001231614795044123456781011   \n",
      "986    991  951234887222659123456781011      \n",
      "987    992  951234887222659123456781011      \n",
      "988    993  951234887222659123456781011      \n",
      "989    994  951234887222659123456781011      \n",
      "990    995  951234887222659123456781011      \n",
      "991    996  951234887222659123456781011      \n",
      "992    997  951234887222659123456781011      \n",
      "993    998  951234887222659123456781011      \n",
      "994    999  951234887222659123456781011      \n",
      "\n",
      "                                               Answers Class Subclass  \n",
      "0    ignoranz den anderen gegenüber.schlecht.die Pe...     M        5  \n",
      "1    mitlachen, mit eingeschlossen zu werden.sie la...     A        5  \n",
      "2    den anderen Umamen, ehrlichkeit, vertrauen.gut...     A        1  \n",
      "3    Sie hält die andere Person, stütz sie. Gut.Sie...     M        1  \n",
      "4    Entspannung, Spaß zu haben. Sie albern herum. ...     A        2  \n",
      "5    Sie unterhalten sich über Dinge, die die die d...     0        0  \n",
      "6    Sie redet aktiv auf die zweite Person ein. übe...     M        4  \n",
      "7    Ruhe zu haben, sie denkt nach.nachdenklich.Sie...     0        0  \n",
      "8    Halt zu kriegen, nach oben zu kommen, Sie klet...     L        3  \n",
      "9    Der zweiten Person zu helfen die \"Kopfnuss\" zu...     M        1  \n",
      "10   Sie beurteilt ein Arbeitsergebnis.mächtig, kon...     M        3  \n",
      "11   Sie bauen ein Gerät zusammen. Wichtig ist die ...     0        0  \n",
      "12   Der zweiten Person zu erklären das Sie einen F...     M        4  \n",
      "13   Der zweite Person Anerkennung zu zeigen..stolz...     M        2  \n",
      "14   Sie hebnt ein großes Gewicht und fühlt sich al...     M        2  \n",
      "15   Der anderen Person seine Ergbenisse zu erläute...     L        2  \n",
      "16   Sie gibt der Gruppe Anweisungen. Wichtig ist I...     M        3  \n",
      "17   Sie mäßregelt die kleinere Person. Wichtig ist...     M        4  \n",
      "18   sie beschützt.gut.weil sie etwas für den ander...     A        3  \n",
      "19   sie reden miteinander.fröhlich.weil sie mitein...     A        2  \n",
      "20   sie lästern über den dritten.unsicher.weil sie...     A        5  \n",
      "21   sie versucht sich zu verteidigen.wie eingesper...     M        3  \n",
      "22   sie denkt nach. für sie ist es wichtig nachzud...     L        1  \n",
      "23   sie will sich retten.in gefahr.weil sie fast r...     L        5  \n",
      "24   sie will ein rätsel lösen.beschützt.weil der a...     L        3  \n",
      "25   für sie ist wichtig dass das kind mal ein arzt...     A        3  \n",
      "26   sie warten dass sie nach hause dürfen.gelangwe...     L        4  \n",
      "27   sie versucht sich zu verteidigen.wütend.weil s...     L        4  \n",
      "28   sie versucht einen auf lieb zu tun.dem anderen...     M        2  \n",
      "29   die einen klatschen, die anderen sind besorgt,...     L        1  \n",
      "..                                                 ...   ...      ...  \n",
      "965  klartext zu reden. anschreien.sicher in dem wa...     M        4  \n",
      "966  das man ihr zuhöhr. auf eine person einreden.g...     M        2  \n",
      "967  was abzugeben. etwas hochhalten.stark.weil sie...     L        2  \n",
      "968  ruhig zu bleiben. rihig da sitzen.hilflos.weil...     M        5  \n",
      "969  das sie das problem vieleicht lösen. aleine da...     A        5  \n",
      "970  auch angehöhrt zu werden. sie schämt sich.alei...     M        5  \n",
      "971  sie möchte gehalten werden und liegt im arm de...     A        4  \n",
      "972  die person lacht sehr laut, sie möchte auf sic...     A        4  \n",
      "973  die person belauscht ein gepräch  sie weiß das...     0        0  \n",
      "974  die person unterhält sich und bietet ihre hand...     A        5  \n",
      "975  die person denkt nach  möchte ein problem löse...     0        0  \n",
      "976  die person erklimmt einen steilen berg  sie mö...     L        2  \n",
      "977  sie versucht eine aufgabe zu lösen, die ihr wi...     L        5  \n",
      "978  sie möchte, dass die andere person ihr verzeih...     M        5  \n",
      "979  sie wollen eine maschine bauen und schneller s...     L        4  \n",
      "980  die person schimpft, weil die andere person ei...     M        4  \n",
      "981  die person möchte auch einmal so groß, stark u...     M        5  \n",
      "982  die person hat einen preis gewonnen und möchte...     M        2  \n",
      "983  die person möchte einerseits mit der anderen p...     M        4  \n",
      "984  sie möchte ein thema vortragen, für das sie si...     M        4  \n",
      "985  die peron schaut zu boden, indem sie am liebst...     M        5  \n",
      "986  Es ist eine Mutter, die ihr Kind umarmt.aktiv,...     M        3  \n",
      "987  sie unterhalten sich über eine witzige Situati...     A        2  \n",
      "988  sie ist eine Außenseiterin und wird in der Kla...     M        5  \n",
      "989  sie wohnt in einer WG, die andere Person ist i...     M        4  \n",
      "990  sie steht an einer Bushaltestelle und friert.i...     A        5  \n",
      "991  sie klettert an einem Hügel hoch.angestrengt, ...     L        3  \n",
      "992  sie sieht sich ihre Bilder an, die andere Pers...     0        0  \n",
      "993  das ist eine Schülerin, die ihr Zeugnis ihrem ...     M        5  \n",
      "994  sie arbeiten auf einem Fließband.müde, konzent...     0        0  \n",
      "\n",
      "[995 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Load Data to pandas frame vor better visualization\n",
    "import pandas as pd\n",
    "complete_data = pd.read_csv('omt_shortned.txt', sep = \";\",\n",
    "                           names = [\"#\",\"Answers\", \"Class\" , \"Subclass\"] )\n",
    "print('before cleaning...\\n')\n",
    "print(complete_data.info(), \"\\n\")\n",
    "print(complete_data[\"Class\"].value_counts(), \"\\n\")\n",
    "#delete eventually empty entries\n",
    "complete_data = complete_data.dropna(axis = 0)\n",
    "#delete eventually wrong labels ('\\N' seems to accure from time to time)\n",
    "complete_data = complete_data.drop(complete_data[complete_data.Class == '\\\\N'].index).reset_index()\n",
    "print('after cleaning...\\n')\n",
    "print(complete_data.info())\n",
    "print(complete_data[\"Class\"].value_counts(), \"\\n\")\n",
    "print(complete_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the needed infos from data_complete\n",
    "data = complete_data.filter([\"Answers\", \"Class\"],axis = 1)\n",
    "\n",
    "#split it into X ( = input) and y ( the labels)\n",
    "X, y = data[\"Answers\"], data[\"Class\"]\n",
    "\n",
    "#split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.1, random_state = 42)\n",
    "\n",
    "\n",
    "#Bei größerem Trainingsset: stratified_shufflesplit nutzen für balancierte sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['schweren', 'unfall', 'neurologischen', 'test', 'bestehen', '.', 'gespannt', 'aufgeregt', 'ängstlich', 'gut', 'test', 'meistern', '.', 'möchte', 'unfähig', 'halten', 'paar', 'schäden', 'unfall', 'zurückbleiben', '.', 'meistert', 'test', 'zufrieden', 'arbeit/unfallnachsorge', 'therapeuten', '.'], ['person', 'schimpft', ',', 'person', 'fehler', 'gemacht', '.', 'einerseits', 'überlegen', ',', 'andererseits', '``', 'oller', 'besserwisser', \"''\", '.weil', 'falle', 'verursacher', ',', 'genau', 'weiß', ',', 'hätte', 'passieren', '.', 'ende', 'sieht', 'fehlverhalten', ',', 'person', 'dennoch', 'gekränkt', '.']]\n",
      "<class 'list'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "# The pattern I (maybe) don't want in my corpus \n",
    "pattern = re.compile(\"\\-|\\!|\\:|\\.|\\d|\\,|\\:|\\(|\\)|\\?|\\\"|\\\\|\\+|\\%|\\/\")\n",
    "def remove_patterns_from_string(strg):\n",
    "    return re.sub(pattern, \" \", strg)\n",
    "\n",
    "# transforms pattern like xyz.Abc to xyz. Abc (--> helps tokenizer to detect sentences)\n",
    "def insert_space_between_special_chars(strg):\n",
    "    return re.sub('([a-zA-Z])([^A-Za-z0-9]+)([a-zA-Z])', r'\\1\\2 \\3', strg)\n",
    "\n",
    "# german stopwords (words who accure very often in texts and don't contribute anything to the text like articles, conjunctions)\n",
    "stopWords = set(stopwords.words(\"german\"))\n",
    "\n",
    "#new spellings\n",
    "stopWords.add('dass')\n",
    "\n",
    "#tokenizes a list of strings\n",
    "#return: list of tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text, language = 'german')\n",
    "    return tokens\n",
    "\n",
    "#retrns: list of strings which do not occure in stopWords\n",
    "def remove_stopwords(text):\n",
    "    return [w for w in text if not w in stopWords]\n",
    "\n",
    "# in : row for row from vector\n",
    "# out: preprocessed version of the row\n",
    "def preprocess_text(corpus):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        #to change xyz.abc to xyz. abc\n",
    "        text = re.sub('([a-zA-Z])(\\.)([a-zA-Z])', r'\\1\\2 \\3', text)\n",
    "        text = text.lower()\n",
    "        #text = remove_patterns_from_string(text)\n",
    "        text = tokenize_text(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "    return normalized_corpus\n",
    "\n",
    "#later preprocess only X_train and X_val. X_test gets its own pipeline in the end\n",
    "X_train_preprocessed = preprocess_text(X_train)\n",
    "X_test_preprocessed = preprocess_text(X_test)\n",
    "\n",
    "\n",
    "print(X_train_preprocessed[:2])\n",
    "print(type(X_train_preprocessed))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       0.00      0.00      0.00        14\n",
      "           L       0.00      0.00      0.00        20\n",
      "           M       0.52      1.00      0.68        52\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       100\n",
      "   macro avg       0.13      0.25      0.17       100\n",
      "weighted avg       0.27      0.52      0.36       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# minimal classification performance: all answers set to M\n",
    "m_labels = []\n",
    "for i in range(len(y_test)):\n",
    "    m_labels.append(\"M\")\n",
    "machtmotiv = pd.Series(m_labels)\n",
    "#plot_classification_report(classification_report(y_test, machtmotiv))\n",
    "print(classification_report(y_test, machtmotiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegression\n",
      "\n",
      "done in 0.019s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       1.00      0.21      0.35        14\n",
      "           L       1.00      0.35      0.52        20\n",
      "           M       0.58      1.00      0.73        52\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       100\n",
      "   macro avg       0.64      0.39      0.40       100\n",
      "weighted avg       0.64      0.62      0.53       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "\n",
      "done in 0.081s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       0.47      0.64      0.55        14\n",
      "           L       0.65      0.55      0.59        20\n",
      "           M       0.67      0.81      0.73        52\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       100\n",
      "   macro avg       0.45      0.50      0.47       100\n",
      "weighted avg       0.54      0.62      0.58       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GradientBoosting\n",
      "\n",
      "done in 27.152s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.07      0.10        14\n",
      "           A       0.33      0.50      0.40        14\n",
      "           L       0.45      0.50      0.48        20\n",
      "           M       0.65      0.63      0.64        52\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       100\n",
      "   macro avg       0.40      0.43      0.40       100\n",
      "weighted avg       0.50      0.51      0.50       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "\n",
      "done in 0.009s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.14      0.21        14\n",
      "           A       0.40      0.86      0.55        14\n",
      "           L       0.65      0.55      0.59        20\n",
      "           M       0.81      0.75      0.78        52\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       100\n",
      "   macro avg       0.56      0.57      0.53       100\n",
      "weighted avg       0.66      0.64      0.63       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_lin\n",
      "\n",
      "done in 0.375s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       0.69      0.64      0.67        14\n",
      "           L       0.82      0.45      0.58        20\n",
      "           M       0.63      0.92      0.75        52\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       100\n",
      "   macro avg       0.54      0.50      0.50       100\n",
      "weighted avg       0.59      0.66      0.60       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SVC_rbf\n",
      "\n",
      "done in 0.336s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       0.00      0.00      0.00        14\n",
      "           L       0.00      0.00      0.00        20\n",
      "           M       0.52      1.00      0.68        52\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       100\n",
      "   macro avg       0.13      0.25      0.17       100\n",
      "weighted avg       0.27      0.52      0.36       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MNB\n",
      "\n",
      "done in 0.008s.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           A       0.00      0.00      0.00        14\n",
      "           L       1.00      0.20      0.33        20\n",
      "           M       0.54      1.00      0.70        52\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       100\n",
      "   macro avg       0.39      0.30      0.26       100\n",
      "weighted avg       0.48      0.56      0.43       100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Test different classifiers from scikit with tfidf model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "test_tfidf = TfidfVectorizer(norm='l2', smooth_idf = True, use_idf = True, ngram_range = (1,2), \n",
    "                                         analyzer = 'word', tokenizer = my_dummy,\n",
    "                                         preprocessor = my_dummy, token_pattern = None)\n",
    "X_train_tfidf = test_tfidf.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = test_tfidf.transform(X_test_preprocessed)\n",
    "\n",
    "names = ['LogRegression',\n",
    "         'RandomForest',\n",
    "         'GradientBoosting',\n",
    "         'KNN',\n",
    "         'SVC_lin',\n",
    "         'SVC_rbf',\n",
    "         'MNB']\n",
    "classifiers = [LogisticRegression(multi_class = 'ovr'),\n",
    "             RandomForestClassifier(),\n",
    "             GradientBoostingClassifier(n_estimators = 200, max_depth = 8),\n",
    "             KNeighborsClassifier(),\n",
    "             SVC(kernel=\"linear\"),\n",
    "              SVC(gamma='scale'),\n",
    "              MultinomialNB(),  \n",
    "             ]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    \n",
    "    time_test = time()\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_predicted_class_test = clf.predict(X_test_tfidf)\n",
    "    class_rep = classification_report(y_test, y_predicted_class_test) \n",
    "    print(name)\n",
    "    print()\n",
    "    print(\"done in %0.3fs.\" % (time() - time_test))\n",
    "    print()\n",
    "    print(class_rep)\n",
    "    print('\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classification with SVC...\n",
      "performing gridsearch...\n",
      "pipeline: ['vect1', 'tf1', 'clf1']\n",
      "parameters:\n",
      "{'vect1__max_df': (0.9, 1.0), 'vect1__ngram_range': ((1, 1), (1, 2), (1, 3)), 'vect1__min_df': (1, 2), 'tf1__use_idf': (True, False), 'clf1__kernel': ('linear', 'rbf'), 'clf1__C': (0.001, 0.1, 1, 10, 100), 'clf1__max_iter': (50, 100, 200)}\n",
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:  6.5min finished\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 391.549s\n",
      "\n",
      "Best score: 0.706\n",
      "best parameters set:\n",
      "\tclf1__C: 1\n",
      "\tclf1__kernel: 'linear'\n",
      "\tclf1__max_iter: 200\n",
      "\ttf1__use_idf: True\n",
      "\tvect1__max_df: 0.9\n",
      "\tvect1__min_df: 1\n",
      "\tvect1__ngram_range: (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# This cell trains SVC classifier with different features (tf, tfidf, min/max _docfrequency, kernels, C, iterations )\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn. decomposition import LatentDirichletAllocation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "print(\"start classification with SVC...\")\n",
    "#define pipeline combining feature extractor with classifier\n",
    "pipeline1 = Pipeline([\n",
    "    ('vect1', CountVectorizer(preprocessor = my_dummy,\n",
    "                              tokenizer =my_dummy, \n",
    "                              token_pattern=None)),\n",
    "                            \n",
    "    ('tf1',TfidfTransformer()),\n",
    "                            \n",
    "    ('clf1', SVC()),    \n",
    "])\n",
    "\n",
    "parameters1 = {\n",
    "    'vect1__max_df': (0.9, 1.0),\n",
    "    'vect1__ngram_range':((1,1),(1,2),(1,3)),\n",
    "    'vect1__min_df': (1,2),\n",
    "    'tf1__use_idf': (True, False),\n",
    "    'clf1__kernel': ('linear','rbf'), \n",
    "    'clf1__C':(0.001,0.1,1,10,100),\n",
    "    'clf1__max_iter':(50,100,200),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #find best params for this feature extraction methods\n",
    "    grid_search1 = GridSearchCV(pipeline1, parameters1, cv=5,\n",
    "                           n_jobs = -1, verbose = 1)\n",
    "    print(\"performing gridsearch...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline1.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parameters1)\n",
    "    time_svc = time()\n",
    "    grid_search1.fit(X_train_preprocessed, y_train)\n",
    "    print(\"done in %0.3fs\" % (time()-time_svc))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search1.best_score_)\n",
    "    print(\"best parameters set:\")\n",
    "    best_parameters = grid_search1.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters1.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classification with RandomForest...\n",
      "performing gridsearch...\n",
      "pipeline: ['vect2', 'clf2']\n",
      "parameters:\n",
      "{'vect2__max_df': (0.9, 0.95, 1.0), 'vect2__ngram_range': ((1, 1), (1, 3)), 'vect2__min_df': (2, 5), 'clf2__n_estimators': (10, 100, 200), 'clf2__criterion': ('gini', 'entropy')}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   43.5s finished\n",
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\classification_omt\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 44.158s\n",
      "\n",
      "Best score: 0.678\n",
      "best parameters set:\n",
      "\tclf2__criterion: 'gini'\n",
      "\tclf2__n_estimators: 200\n",
      "\tvect2__max_df: 1.0\n",
      "\tvect2__min_df: 5\n",
      "\tvect2__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn. decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "print(\"start classification with RandomForest...\")\n",
    "#define pipeline combining feature extractor with classifier\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect2', CountVectorizer(preprocessor = my_dummy,\n",
    "                              tokenizer =my_dummy, \n",
    "                              token_pattern=None)),\n",
    "                            \n",
    "                            \n",
    "    ('clf2', RandomForestClassifier()),    \n",
    "])\n",
    "\n",
    "parameters2 = {\n",
    "    'vect2__max_df': (0.9,0.95,1.0),\n",
    "    'vect2__ngram_range':((1,1),(1,3)),\n",
    "    'vect2__min_df': (2,5), \n",
    "    'clf2__n_estimators':(10,100,200), \n",
    "    'clf2__criterion': ('gini','entropy'),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #find best params for this feature extraction methods\n",
    "    grid_search2 = GridSearchCV(pipeline2, parameters2, cv=5,\n",
    "                           n_jobs = -1, verbose = 1)\n",
    "    print(\"performing gridsearch...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline2.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parameters2)\n",
    "    time_svc = time()\n",
    "    grid_search2.fit(X_train_preprocessed, y_train)\n",
    "    print(\"done in %0.3fs\" % (time()-time_svc))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search2.best_score_)\n",
    "    print(\"best parameters set:\")\n",
    "    best_parameters = grid_search2.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters2.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classification with SVC and extra LDA - Features...\n",
      "performing randomizedsearch...\n",
      "pipeline: ['union1', 'clf5']\n",
      "parameters:\n",
      "{'union1__vect3__max_df': [0.9, 1.0], 'union1__vect3__ngram_range': [(1, 1), (1, 3)], 'union1__vect3__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018E2F57A9E8>, 'union1__pipe1__vect_lda1__ngram_range': [(1, 1)], 'union1__pipe1__lda1__n_components': [3, 10], 'union1__pipe1__lda1__learning_offset': [5], 'clf5__kernel': ('linear',), 'clf5__C': [0.01, 0.1, 1, 10], 'clf5__max_iter': [100]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn. decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "print(\"start classification with SVC and extra LDA - Features...\")\n",
    "#define pipeline combining feature extractor with classifier\n",
    "pipeline5 = Pipeline([\n",
    "    ('union1', FeatureUnion(n_jobs = -1,\n",
    "                          transformer_list = [\n",
    "                              ('vect3', CountVectorizer(preprocessor = my_dummy,\n",
    "                                                        tokenizer =my_dummy, \n",
    "                                                        token_pattern=None)),\n",
    "                                  \n",
    "                            \n",
    "    \n",
    "                              \n",
    "                              ('pipe1', Pipeline([\n",
    "                                  ('vect_lda1', CountVectorizer(preprocessor = my_dummy,\n",
    "                                                               tokenizer =my_dummy, token_pattern=None)),\n",
    "                                   ('lda1', LatentDirichletAllocation(max_iter = 100, learning_method = 'online'))\n",
    "                              ]))\n",
    "                            ])),\n",
    "                            \n",
    "    ('clf5', SVC()),    \n",
    "])\n",
    "\n",
    "parameters5 = {\n",
    "    'union1__vect3__max_df': [0.9,1.0],\n",
    "    'union1__vect3__ngram_range':[(1,1),(1,3)],\n",
    "    'union1__vect3__min_df': sp_randint(1,10),\n",
    "    'union1__pipe1__vect_lda1__ngram_range':[(1,1)],\n",
    "    'union1__pipe1__lda1__n_components': [3,10],\n",
    "    'union1__pipe1__lda1__learning_offset': [5],\n",
    "    'clf5__kernel': ('linear',), \n",
    "    'clf5__C': [0.01,0.1,1,10],\n",
    "    'clf5__max_iter': [100],\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #find best params for this feature extraction methods\n",
    "    randomizedSearch1 = RandomizedSearchCV(pipeline5, n_iter = 10,\n",
    "                                           param_distributions =parameters5, cv=3,\n",
    "                                           n_jobs = -1,)\n",
    "    print(\"performing randomizedsearch...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline5.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parameters5)\n",
    "    time_svc = time()\n",
    "    randomizedSearch1.fit(X_train_preprocessed, y_train)\n",
    "    print(\"done in %0.3fs\" % (time()-time_svc))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % randomizedSearch1.best_score_)\n",
    "    print(\"best parameters set:\")\n",
    "    best_parameters = randomizedSearch1.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters5.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
